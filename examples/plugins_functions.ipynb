{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xXnd1cCu1TkJ"
      },
      "source": [
        "# Use Plugins with GPT Functions\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/edreisMD/plugnplai/blob/main/examples/plugins_step_by_step.ipynb)\n",
        "\n",
        "The goal of this example is to go through all the steps to add plugins to LLMs\n",
        "1. Get plugins of certain categories from [plugnplai.com](https://plugnplai.com)\n",
        "2. Load plugins manifest and specifications\n",
        "3. Parse specifications and generate a prompt with the descriptions\n",
        "4. Use [LangChain]() to call the LLM\n",
        "5. Parse the LLM response, looking for the `[API]` pattern defined on `plugins.prompt`\n",
        "6. Call the plugin using `plugins.call()`\n",
        "7. Use LangChain again to ask the LLM a final response using the new data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OZWQil8RrAKV"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RUcr3tLEK7M",
        "outputId": "1d23a54a-d77d-4090-97a9-108d2870cae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://test.pypi.org/simple/\n",
            "Requirement already satisfied: plugnplai==0.0.22a1 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (0.0.22a1)\n",
            "Requirement already satisfied: faiss-cpu<2.0.0,>=1.7.4 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from plugnplai==0.0.22a1) (1.7.4)\n",
            "Requirement already satisfied: jsonref<2.0.0,>=1.1.0 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from plugnplai==0.0.22a1) (1.1.0)\n",
            "Requirement already satisfied: langchain<0.0.161,>=0.0.160 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from plugnplai==0.0.22a1) (0.0.160)\n",
            "Requirement already satisfied: openai<0.28.0,>=0.27.6 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from plugnplai==0.0.22a1) (0.27.6)\n",
            "Requirement already satisfied: pydantic<2.0.0,>=1.10.7 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from plugnplai==0.0.22a1) (1.10.7)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /bmrNAS/people/edreis/.local/lib/python3.10/site-packages (from plugnplai==0.0.22a1) (6.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.2 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from plugnplai==0.0.22a1) (2.28.2)\n",
            "Requirement already satisfied: tiktoken<0.4.0,>=0.3.3 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from plugnplai==0.0.22a1) (0.3.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /bmrNAS/people/edreis/.local/lib/python3.10/site-packages (from langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (1.4.46)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /bmrNAS/people/edreis/.local/lib/python3.10/site-packages (from langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (3.8.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /bmrNAS/people/edreis/.local/lib/python3.10/site-packages (from langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (0.5.7)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /bmrNAS/people/edreis/.local/lib/python3.10/site-packages (from langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (1.24.2)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (1.2.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /bmrNAS/people/edreis/.local/lib/python3.10/site-packages (from langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (8.2.2)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /bmrNAS/people/edreis/.local/lib/python3.10/site-packages (from langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /bmrNAS/people/edreis/.local/lib/python3.10/site-packages (from pydantic<2.0.0,>=1.10.7->plugnplai==0.0.22a1) (4.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /bmrNAS/people/edreis/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.2->plugnplai==0.0.22a1) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.2->plugnplai==0.0.22a1) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.2->plugnplai==0.0.22a1) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.2->plugnplai==0.0.22a1) (2022.12.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /bmrNAS/people/edreis/.local/lib/python3.10/site-packages (from tiktoken<0.4.0,>=0.3.3->plugnplai==0.0.22a1) (2023.3.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /bmrNAS/people/edreis/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /bmrNAS/people/edreis/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /bmrNAS/people/edreis/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /bmrNAS/people/edreis/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /bmrNAS/people/edreis/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (0.8.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /bmrNAS/people/edreis/.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (2.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (21.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (1.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain<0.0.161,>=0.0.160->plugnplai==0.0.22a1) (3.0.9)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -i https://test.pypi.org/simple/ plugnplai==0.0.22a1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0.22a1\n"
          ]
        }
      ],
      "source": [
        "import plugnplai as pl\n",
        "\n",
        "print(pl.__version__)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7fYY9i4Z3sBO"
      },
      "source": [
        "# Get the plugins"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nlC-9wyp2vtF"
      },
      "source": [
        "We want to install at maximum three plugins, in order to fit the description on the context length\n",
        "\n",
        "Lets find one plugin for each category:\n",
        "1. travel\n",
        "2. shopping\n",
        "3. weather\n",
        "\n",
        "We can use PlugnPlai categories (see [API reference](https://plugnplai.github.io/))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmqqHyg5Eee0",
        "outputId": "f4d877f4-daeb-4701-e24d-1721fb07cb23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Our chosen Plugins: ['https://klarna.com']\n"
          ]
        }
      ],
      "source": [
        "import plugnplai as pl\n",
        "# Get working plugins - only tested plugins (in progress)\n",
        "allUrls = pl.get_plugins()\n",
        "\n",
        "# Lets pick Trip, Klarna and Speak\n",
        "urls = [plugin for plugin in allUrls if 'klarna' in plugin]\n",
        "\n",
        "print(f'Our chosen Plugins: {urls}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hj5MtCaPyk9p"
      },
      "source": [
        "# Load and activate the plugins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JMHi1UTpy8LV"
      },
      "outputs": [],
      "source": [
        "from plugnplai import Plugins\n",
        "\n",
        "plugins = Plugins.install_and_activate(urls)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2-alHvKpyk9q"
      },
      "source": [
        "## Show the function object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g770AOGZ0vwH",
        "outputId": "eaf4c814-518f-4fd5-b299-8c0a83d31322"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'KlarnaProducts__opid__productsUsingGET',\n",
              "  'description': 'Assistant uses the Klarna plugin to get relevant product suggestions for any shopping or product discovery purpose. Assistant will reply with the following 3 paragraphs 1) Search Results 2) Product Comparison of the Search Results 3) Followup Questions. The first paragraph contains a list of the products with their attributes listed clearly and concisely as bullet points under the product, together with a link to the product and an explanation. Links will always be returned and should be shown to the user. The second paragraph compares the results returned in a summary sentence starting with \"In summary\". Assistant comparisons consider only the most important features of the products that will help them fit the users request, and each product mention is brief, short and concise. In the third paragraph assistant always asks helpful follow-up questions and end with a question mark. When assistant is asking a follow-up question, it uses it\\'s product expertise to provide information pertaining to the subject of the user\\'s request that may guide them in their search for the right product.',\n",
              "  'parameters': {'countryCode': {'type': 'string',\n",
              "    'description': 'ISO 3166 country code with 2 characters based on the user location. Currently, only US, GB, DE, SE and DK are supported.',\n",
              "    'required': True},\n",
              "   'q': {'type': 'string',\n",
              "    'description': \"A precise query that matches one very small category or product that needs to be searched for to find the products the user is looking for. If the user explicitly stated what they want, use that as a query. The query is as specific as possible to the product name or category mentioned by the user in its singular form, and don't contain any clarifiers like latest, newest, cheapest, budget, premium, expensive or similar. The query is always taken from the latest topic, if there is a new topic a new query is started. If the user speaks another language than English, translate their request into English (example: translate fia med knuff to ludo board game)!\",\n",
              "    'required': True},\n",
              "   'size': {'type': 'integer',\n",
              "    'description': 'number of products returned',\n",
              "    'required': False},\n",
              "   'min_price': {'type': 'integer',\n",
              "    'description': \"(Optional) Minimum price in local currency for the product searched for. Either explicitly stated by the user or implicitly inferred from a combination of the user's request and the kind of product searched for.\",\n",
              "    'required': False},\n",
              "   'max_price': {'type': 'integer',\n",
              "    'description': \"(Optional) Maximum price in local currency for the product searched for. Either explicitly stated by the user or implicitly inferred from a combination of the user's request and the kind of product searched for.\",\n",
              "    'required': False}}}]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plugins.functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "plugins.functions[0][\"description\"] = \"Assistant uses the Klarna plugin to get relevant product suggestions for any shopping or product discovery purpose.\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z_WvLZ5yk9q"
      },
      "source": [
        "## Lets look at the length of the prompt\n",
        "\n",
        "Get the number of tokens of the prompt by just calling 'plugins.tokens'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnFld3xszdrx",
        "outputId": "04c0bfc3-45bd-471e-8519-f8cee2bac075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "573\n"
          ]
        }
      ],
      "source": [
        "print(plugins.func_tokens)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ikGFVxvPyk9q"
      },
      "source": [
        "## Call the LLM with functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QTKMtRiMyk9r"
      },
      "outputs": [],
      "source": [
        "# You will need to first define your API key\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "N1C-RZvUyk9r"
      },
      "source": [
        "#### Uncomment or modify the message to test different plugins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EFc4Xw3Dyk9r"
      },
      "outputs": [],
      "source": [
        "# Test Klarna Plugin\n",
        "HUMAN_MESSAGE = \"I want to buy a rolling stones t-shirt\"\n",
        "\n",
        "# Test Trip Plugin\n",
        "# HUMAN_MESSAGE = \"I need a hotel in Paris between Dec.3-8\"\n",
        "\n",
        "# Test Speak Plugin\n",
        "# HUMAN_MESSAGE = \"How to say I love you in Portuguese?\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z-JDpX0Uyk9r"
      },
      "source": [
        "#### Call LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S5B0ibJyk9r",
        "outputId": "08049290-519e-45a3-b750-cf8b983f5281"
      },
      "outputs": [
        {
          "ename": "InvalidRequestError",
          "evalue": "Invalid schema for function 'KlarnaProducts__opid__productsUsingGET': schema must be a JSON Schema of 'type: \"object\"', got 'type: \"None\"'.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m         second_response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m             model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-4\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m             messages\u001b[39m=\u001b[39mmessages,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m         )  \u001b[39m# get a new response from GPT where it can see the function response\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m second_response\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mprint\u001b[39m(run_conversation())\n",
            "\u001b[1;32m/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb Cell 20\u001b[0m in \u001b[0;36mrun_conversation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Use 'plugins.functions' on the gpt call \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m functions \u001b[39m=\u001b[39m plugins\u001b[39m.\u001b[39mfunctions\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-4\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     functions\u001b[39m=\u001b[39;49mfunctions,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m# auto is default, but here we will force GPT to call the function\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     function_call\u001b[39m=\u001b[39;49m {\u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mKlarnaProducts__opid__productsUsingGET\u001b[39;49m\u001b[39m\"\u001b[39;49m},\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m response_message \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btorino.stanford.edu/dataNAS/people/edreis/plugnplai-func2/examples/plugins_functions.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Step 2: check if GPT wanted to call a function\u001b[39;00m\n",
            "File \u001b[0;32m/bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
            "File \u001b[0;32m/bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
            "File \u001b[0;32m/bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages/openai/api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
            "File \u001b[0;32m/bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages/openai/api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    619\u001b[0m         )\n\u001b[1;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    629\u001b[0m         ),\n\u001b[1;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m     )\n",
            "File \u001b[0;32m/bmrNAS/people/edreis/miniconda/envs/rainbow/lib/python3.10/site-packages/openai/api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    689\u001b[0m     )\n\u001b[1;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: Invalid schema for function 'KlarnaProducts__opid__productsUsingGET': schema must be a JSON Schema of 'type: \"object\"', got 'type: \"None\"'."
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import json\n",
        "\n",
        "def use_call_api(response_message):\n",
        "    \n",
        "    function_name = response_message[\"function_call\"][\"name\"]\n",
        "    split_name = function_name.split(\"__opid__\")\n",
        "    plugin_name = split_name[0]\n",
        "    operation_id = split_name[1]\n",
        "    parameters = response_message[\"function_call\"][\"arguments\"]\n",
        "    \n",
        "    r = plugins.call_api(plugin_name = plugin_name,\n",
        "                        operation_id = operation_id,\n",
        "                        parameters = parameters\n",
        "                        )\n",
        "\n",
        "    api_response = r.json()\n",
        "    return r.json()\n",
        "\n",
        "\n",
        "def run_conversation():\n",
        "    # Step 1: send the conversation and available functions to GPT\n",
        "    messages = [{\"role\": \"user\", \"content\": HUMAN_MESSAGE}]\n",
        "    \n",
        "    # Use 'plugins.functions' on the gpt call \n",
        "    functions = plugins.functions\n",
        "    \n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=messages,\n",
        "        functions=functions,\n",
        "        # auto is default, but here we will force GPT to call the function\n",
        "        function_call= {\"name\": \"KlarnaProducts__opid__productsUsingGET\"},\n",
        "    )\n",
        "    \n",
        "    response_message = response[\"choices\"][0][\"message\"]\n",
        "\n",
        "    # Step 2: check if GPT wanted to call a function\n",
        "    if response_message.get(\"function_call\"):\n",
        "        # Step 3: call the function\n",
        "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
        "        \n",
        "        # now use plugins.call_api defined on the use_call_api above\n",
        "        function_response = use_call_api(response_message)\n",
        "\n",
        "        # Step 4: send the info on the function call and function response to GPT\n",
        "        messages.append(response_message)  # extend conversation with assistant's reply\n",
        "        messages.append(\n",
        "            {\n",
        "                \"role\": \"function\",\n",
        "                \"name\": response_message[\"function_call\"][\"name\"],\n",
        "                \"content\": function_response,\n",
        "            }\n",
        "        )  # extend conversation with function response\n",
        "        second_response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=messages,\n",
        "        )  # get a new response from GPT where it can see the function response\n",
        "        return second_response\n",
        "\n",
        "\n",
        "print(run_conversation())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "plugnplai-nyjYP0nS-py3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
